
export ROCBLAS_LAYER=2
export MIOPEN_ENABLE_LOGGING_CMD=1

set -x
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m bert-base-cased --sequence_length 384 --batch_sizes 1 2 64 -t 1 --provider=migraphx -p fp16 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/attention_models
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m bert-base-cased --sequence_length 384 --batch_sizes 1 2 64 -t 1 --provider=migraphx -p fp32 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/attention_models
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m bert-base-cased --sequence_length 384 --batch_sizes 1 2 64 -t 1 --provider=migraphx -p fp16 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/onnx_models  --disable_layer_norm --disable_attention
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m bert-base-cased --sequence_length 384 --batch_sizes 1 2 64 -t 1 --provider=migraphx -p fp32 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/onnx_models  --disable_layer_norm --disable_attention
#
#
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m bert-large-uncased --sequence_length 384 --batch_sizes 1 2 32 -t 1 --provider=migraphx -p fp16 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/attention_models
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m bert-large-uncased --sequence_length 384 --batch_sizes 1 2 32 -t 1 --provider=migraphx -p fp32 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/attention_models
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m bert-large-uncased --sequence_length 384 --batch_sizes 1 2 32 -t 1 --provider=migraphx -p fp16 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/onnx_models  --disable_layer_norm --disable_attention
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m bert-large-uncased --sequence_length 384 --batch_sizes 1 2 32 -t 1 --provider=migraphx -p fp32 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/onnx_models  --disable_layer_norm --disable_attention
#
#
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m distilgpt2 --sequence_length 384 --batch_sizes 1 2 16 -t 1 --provider=migraphx -p fp16 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/attention_models
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m distilgpt2 --sequence_length 384 --batch_sizes 1 2 16 -t 1 --provider=migraphx -p fp32 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/attention_models
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m distilgpt2 --sequence_length 384 --batch_sizes 1 2 16 -t 1 --provider=migraphx -p fp16 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/onnx_models  --disable_layer_norm --disable_attention
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m distilgpt2 --sequence_length 384 --batch_sizes 1 2 16 -t 1 --provider=migraphx -p fp32 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/onnx_models  --disable_layer_norm --disable_attention
#
#for bs in {1,2,8,32,64,256,1024}
#do
  #migraphx-driver run /workspace/mlperf/dlrm_top.onnx --batch $bs 
  #migraphx-driver run /workspace/mlperf/dlrm_top.onnx --fp16 --batch $bs 
#done
#
#for bs in {1,2,8,32,64,256,1024}
#do
  #migraphx-driver run /workspace/mlperf/dlrm_bot.onnx --batch $bs 
  #migraphx-driver run /workspace/mlperf/dlrm_bot.onnx --fp16 --batch $bs 
#done


## This is the Bert used in MLPerf
##for bs in {1,2,64}
#do
  #migraphx-driver run /workspace/mlperf/bert.onnx --fill1 input_ids --fill1 segment_ids --input-dim @input_ids $bs 384 --fp16 2>&1 |tee trace_bert.out
  #migraphx-driver run /workspace/mlperf/bert.onnx --fill1 input_ids --fill1 segment_ids --input-dim @input_ids $bs 384  2>&1 |tee trace_bert.out 
#done
#
## This is the Bert used in ONNX Model Zoo
#for bs in {1,2,64}
#do
  #migraphx-driver run /workspace/mlperf/bertsquad-12.onnx --fill1 input_ids:0 --fill1 input_mask:0 --fill1 segment_ids:0 --fp16 --batch $bs 2>&1 |tee trace_bertsquad.out
  #migraphx-driver run /workspace/mlperf/bertsquad-12.onnx --fill1 input_ids:0 --fill1 input_mask:0 --fill1 segment_ids:0  --batch $bs 2>&1 |tee trace_bertsquad.out
#done
#
## 3dunet downloaded from https://github.com/mlcommons/inference/tree/master/vision/medical_imaging/3d-unet-kits19
#for bs in {1,2,64}
#do
  #migraphx-driver perf /workspace/mlperf/3dunet_kits19_128x128x128.onnx --batch $bs 2>&1 |tee trace_3dunet.out
#done


#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m gpt2-large --sequence_length 384 --batch_sizes 1 2 64 -t 1 --provider=migraphx -p fp32 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/onnx_models  --disable_layer_norm --disable_attention
#
#python /workspace/onnxruntime/build/Release/onnxruntime/transformers/benchmark.py -g -m gpt2-large --sequence_length 384 --batch_sizes 1 2 64 -t 1 --provider=migraphx -p fp16 --disable_gelu  --disable_skip_layer_norm --disable_embed_layer_norm --disable_bias_skip_layer_norm --disable_bias_gelu  --onnx_dir /workspace/benchmarking/onnx_models  --disable_layer_norm --disable_attention
#
#for bs in {1,2,64}
#do
  #migraphx-driver run /workspace/benchmarking/onnx_models/gpt2_large_1/gpt2_large_1.onnx  --batch $bs --fill1 input_ids  2>&1|tee trace_gpt2large.out
  #migraphx-driver run /workspace/benchmarking/onnx_models/gpt2_large_1_fp16_gpu/gpt2_large_1_fp16_gpu.onnx  --batch $bs --fill1 input_ids 2>&1|tee trace_gpt2large.out
#done
#
# RESNET50
# Take from MLPerf https://zenodo.org/record/4735647/files/resnet50_v1.onnx 
for bs in {1,2,64}
do
  migraphx-driver perf /workspace/mlperf/resnet50_v1.onnx --batch $bs 2>&1|tee trace_resnet50.out
  migraphx-driver perf /workspace/mlperf/resnet50_v1.onnx --batch $bs --fp16 2>&1|tee trace_resnet50.out
done


