#!/bin/bash
export MIGRAPHX_MLIR_DUMP_TO_MXR=$(pwd)/mlir
export MIGRAPHX_MLIR_USE_SPECIFIC_OPS=dot,convolution,~fused,~attention

rm $MIGRAPHX_MLIR_DUMP_TO_MXR/*.mxr

function run_test {
    title=$1
    env_vars=$2
    modelname=$3
    modelparms=$4
    modeldatatype=$5

    (( COUNTER++ ))

    rm $MIGRAPHX_MLIR_DUMP_TO_MXR/*.mxr
    ( if [ -n "$env_vars" ]; then export $env_vars; fi; time migraphx-driver compile $modelname $modelparms $modeldatatype ) 

    files=($MIGRAPHX_MLIR_DUMP_TO_MXR/*.mxr)
    
    for filename in ${files[@]} ; 
    do
	ofile="${filename/.mxr/".py"}"
	echo $ofile
        ( if [ -n "$env_vars" ]; then export $env_vars; fi; time migraphx-driver read  $filename --py -o $ofile );
    done

    rm $MIGRAPHX_MLIR_DUMP_TO_MXR/*.mxr
}

while read testcase params
do
    if [[ $testcase =~ ^# ]]; then
        continue;
    fi

    #for datatype in " " "--fp16" "--fp16 --int8" "--int8" "--fp16 --fp8" "--fp8" ; do
    for datatype in "--fp16" ; do

	run_test "DOT0 NHWC0" "MIGRAPHX_ENABLE_REWRITE_DOT=0 MIGRAPHX_ENABLE_NHWC=0" "$testcase" "$params" "$datatype"
        run_test "DOT0 NHWC1" "MIGRAPHX_ENABLE_REWRITE_DOT=0 MIGRAPHX_ENABLE_NHWC=1" "$testcase" "$params" "$datatype"
        run_test "DOT1 NHWC0" "MIGRAPHX_ENABLE_REWRITE_DOT=1 MIGRAPHX_ENABLE_NHWC=0" "$testcase" "$params" "$datatype"
        run_test "DOT1 NHWC1" "MIGRAPHX_ENABLE_REWRITE_DOT=1 MIGRAPHX_ENABLE_NHWC=1" "$testcase" "$params" "$datatype"

    done

done <<TESTLIST
/models/mlperf/resnet50_v1.onnx --batch 1
/models/mlperf/resnet50_v1.onnx --batch 64
/models/mlperf/resnet50_v1.onnx --batch 512
/models/ORT/onnx_models/bert_base_cased_1.onnx  --fill1 input_ids --input-dim @input_ids 1 384
/models/ORT/onnx_models/bert_base_cased_1.onnx  --fill1 input_ids --input-dim @input_ids 64 384 --batch 64
/models/ORT/onnx_models/bert_base_cased_1.onnx  --fill1 input_ids --input-dim @input_ids 256 384 --batch 256
/models/ORT/onnx_models/bert_base_cased_1.onnx  --fill1 input_ids --input-dim @input_ids 1 32
/models/ORT/onnx_models/bert_base_cased_1.onnx  --fill1 input_ids --input-dim @input_ids 64 32 --batch 64
/models/ORT/onnx_models/bert_large_uncased_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 1 384
/models/ORT/onnx_models/bert_large_uncased_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 32 384 --batch 32
/models/ORT/onnx_models/bert_large_uncased_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 256 384 --batch 256
/models/ORT/onnx_models/bert_large_uncased_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 1 32
/models/ORT/onnx_models/bert_large_uncased_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 32 32 --batch 32
/models/ORT/onnx_models/distilgpt2_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 1 384
/models/ORT/onnx_models/distilgpt2_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 16 384 --batch 16
/models/ORT/onnx_models/distilgpt2_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 256 384 --batch 256
/models/ORT/onnx_models/distilgpt2_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 1 32
/models/ORT/onnx_models/distilgpt2_1_fp16_gpu.onnx  --fill1 input_ids --input-dim @input_ids 16 32 --batch 16
/models/onnx-model-zoo/gpt2-10.onnx --batch 1
/models/sd/unet/model.onnx --input-dim @sample 2 4 64 64 @timestep 1 @encoder_hidden_states 2 64 1024 --batch 2
/models/sd/unet/model.onnx --input-dim @sample 8 4 64 64 @timestep 1 @encoder_hidden_states 8 64 1024 --batch 8
/models/sd/unet/model.onnx --input-dim @sample 64 4 64 64 @timestep 1 @encoder_hidden_states 64 64 1024 --batch 64
/models/sdxl/unet/model.onnx --input-dim @sample 2 4 128 128 @timestep 1 @encoder_hidden_states 2 77 2048 @time_ids 2 6 @text_embeds 2 1280 --batch 2
/models/bert/bertsquad-12.onnx --fill1 input_ids:0 --fill1 input_mask:0 --fill1 segment_ids:0
/models/mlperf/bert_large_mlperf.onnx --fill1 input_ids --fill1 input_mask --fill1 segment_ids
/models/torchvision/resnet50i64.onnx --batch 64
/models/torchvision/densenet121i32.onnx --batch 32
/models/torchvision/inceptioni32.onnx --batch 32
/models/cadene/inceptionv4i16.onnx --batch 16
/models/cadene/resnext101_64x4di16.onnx --batch 16
/models/slim/mobilenet_i64.pb --batch 64
/models/slim/nasnet_i64.pb --batch 64
/models/slim/resnet50v2_i64.pb --batch 64
/models/huggingface-transformers/bert_mrpc8.onnx --fill1 input.1 --fill1 input.5 --fill1 onnx::Unsqueeze_1 --onnx --batch 8
/models/tf-misc/bert_mrpc1.pb --fill1 input_ids_1 --fill1 segment_ids_1 --fill1 input_mask_1 --tf --batch 1
/models/pytorch-examples/wlang_gru.onnx --fill0 input.1 --onnx
/models/pytorch-examples/wlang_lstm.onnx --fill0 input.1 --onnx
/models/torchvision/resnet50i1.onnx
/models/torchvision/inceptioni1.onnx
/models/cadene/dpn92i1.onnx
/models/cadene/resnext101_64x4di1.onnx
/models/slim/vgg16_i1.pb
/models/slim/mobilenet_i1.pb
/models/slim/inceptionv4_i1.pb
/models/onnx-misc/taau_low_res_downsample_d2s_for_infer_time_fp16_opset11.onnx --input-dim @inputs 1 1920 1080 8
/models/agentmodel/AgentModel.onnx
/models/bert/bert-large-uncased.onnx --input-dim @input_ids 32 32 @attention_mask 32 32 @token_type_ids 32 32 --fill1 input_ids attention_mask token_type_ids --batch 32
/models/bert/bert-large-uncased.onnx --input-dim @input_ids 32 384 @attention_mask 32 384 @token_type_ids 32 384 --fill1 input_ids attention_mask token_type_ids --batch 32
/models/bert/bert-large-uncased.onnx --input-dim @input_ids 1 32 @attention_mask 1 32 @token_type_ids 1 32 --fill1 input_ids attention_mask token_type_ids
/models/bert/bert-large-uncased.onnx --input-dim @input_ids 1 384 @attention_mask 1 384 @token_type_ids 1 384 --fill1 input_ids attention_mask token_type_ids
/models/UIF/pt_albert_basev1.5_1.2_M2.6/float/onnx_albert_base_qa/pt_albert_base_0_0_fp32.onnx  --fill1 attention_mask --fill1 token_type_ids --fill1 input_ids --input-dim @input_ids 1 384
/models/UIF/pt_wd_1.2_M2.6/float/pt_wd_fp32.onnx  --fill1 input
/models/UIF/pt_gpt2_medium_1.2_M2.6/float/onnx_gpt2-medium/pt_gpt2_medium_fp32.onnx --fill1 input_ids 
/models/UIF/pt_3dunet_1.2_M2.6/float/pt_3dunet_0_0_fp32.onnx
/models/UIF/pt_3dunet_1.2_M2.6/float/pt_3dunet_0_32_fp32.onnx
/models/UIF/pt_pointpillars_1.2_M2.6/float/pt_pointpillars_0_0_fp32.onnx  --fill1 voxels --fill1 coors
/models/UIF/pt_detr_1.2_M2.6/float/onnx/detr_r50_fp32.onnx
/models/UIF/tf2_bert_largev1.5_1.2_M2.6/float/onnx_model/tf2_bert_large_0_0_fp32.onnx
/models/UIF/pt_vit_1.2_M2.6/float/pt_vit_0_0_fp32.onnx
/models/UIF/pt_gpt2_large_1.2_M2.6/float/onnx_gpt2-large/fp32/pt_gpt2_large_fp32.onnx
/models/UIF/pt_retinanet_1.2_M2.6/float/pt_retinanet_fp32.onnx
/models/UIF/pt_detr_onnx/pt_detr_fp32.onnx
/models/UIF/tf2_bert_basev1.5_1.2_M2.6/float/onnx_model/tf2_bert_base_0_0_fp32.onnx
/models/UIF/pt_mobilebertv1.5_1.2_M2.6/float/onnx_mobilebert_qa/pt_mobilebert_0_0_fp32.onnx  --fill1 attention_mask --fill1 token_type_ids --fill1 input_ids --fp16 --input-dim @input_ids 1 384
/models/UIF/pt_distilbertv1.5_1.2_M2.6/float/onnx_distilbert_squadv_qa/pt_distilbert_0_0_fp32.onnx --fill1 attention_mask --fill1 input_ids
/models/UIF/tf2_2dunet_0.7_1.2_M2.6/float/tf2_2dunet_prune_0.7_fp32.onnx
/models/UIF/pt_ofa_resnet_0.88_1.2_M2.6/float/pt_ofa_resnet_0.88_0_fp32.onnx
/models/UIF/tf2_yolov3_1.2_M2.6/float/tf2_yolov3_0_0_fp32.onnx
/models/UIF/pt_albert_largev1.5_1.2_M2.6/float/onnx_albert_large_qa/pt_albert_large_0_0_fp32.onnx  --fill1 attention_mask --fill1 token_type_ids --fill1 input_ids --input-dim @input_ids 1 384
/models/sd/stable-diffusion-2-onnx/unet/model.onnx  --input-dim @sample 2 4 64 64 @timestep 1 @encoder_hidden_states 2 64 1024
/models/sd/stable-diffusion-2-onnx/text_encoder/model.onnx
/models/sd/stable-diffusion-2-onnx/vae_decoder/model.onnx --input-dim @latent_sample 1 4 64 64 -t 482
/models/llama2_7b/decoder_model.onnx --fill1 input_ids attention_mask --input-dim @input_ids 1 256 @attention_mask 1 256
/models/qwen1.5-7b/model.onnx --fill1 input_ids attention_mask position_ids --input-dim @input_ids 1 256 @attention_mask 1 256 @position_ids 1 256
/models/phi3-3.8b/model.onnx --fill1 input_ids attention_mask position_ids --input-dim @input_ids 1 256 @attention_mask 1 256 @position_ids 1 256
/models/mask-rcnn/MaskRCNN-10.onnx --input-dim @image 3 800 800
/models/llama3-8b/model.onnx --fill1 input_ids attention_mask position_ids --input-dim @input_ids 1 256 @attention_mask 1 256 @position_ids 1 256
/models/whisper-large/encoder_model.onnx --input-dim @input_features 1 80 3000
/models/whisper-large/decoder_model.onnx --fill1 input_ids --input-dim @input_ids 1 216 @encoder_hidden_states 1 1 1280
/models/mistral-7b/model.onnx --fill1 input_ids attention_mask position_ids --input-dim @input_ids 1 256 @attention_mask 1 256 @position_ids 1 256
/models/FLUX.1-schnell/text_encoder/model.onnx --fill1 input_ids
/models/sd3/text_encoder/model.onnx --input-dim @input_ids 1 77  --fill1 input_ids
/models/sd3/text_encoder_2/model.onnx --input-dim @input_ids 1 77  --fill1 input_ids
/models/sd3/text_encoder_3/model.onnx --input-dim @input_ids 1 77  --fill1 input_ids
/models/sd3.5/text_encoder/model.onnx --input-dim @input_ids 1 77  --fill1 input_ids
/models/sd3.5/text_encoder_2/model.onnx --input-dim @input_ids 1 77  --fill1 input_ids
/models/sd3.5/text_encoder_3/model.onnx --input-dim @input_ids 1 77  --fill1 input_ids
/models/yolov10/yolov10n_1.onnx --input-dim @images 1 3 640 640
/models/yolov4.onnx
/models/sd3_medium/vae_encoder/model.onnx --input-dim @sample 1 3 64 64
TESTLIST
